{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ORB Detector Parameter Tuning \n",
    "## Setup the required functions and input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb  1 20:06:06 2019\n",
    "\n",
    "@author: vik748\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from ssc import *\n",
    "%matplotlib inline\n",
    "from scipy import spatial\n",
    "import time\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "\n",
    "#from mahotas import features\n",
    "\n",
    "def draw_keypoints(vis_orig, keypoints, color = (255, 255, 0), thick = 1):\n",
    "    vis = vis_orig.copy()\n",
    "    for kp in keypoints:\n",
    "        x, y = kp.pt\n",
    "        cv2.circle(vis, (int(x), int(y)), int(vis.shape[1]/200), color, thickness=thick)\n",
    "    return vis\n",
    "\n",
    "def draw_markers(vis_orig, keypoints, color = (0, 0, 255)):\n",
    "    vis = vis_orig.copy()\n",
    "    for kp in keypoints:\n",
    "        x, y = kp.pt\n",
    "        cv2.drawMarker(vis, (int(x), int(y)), color,  markerSize=30, markerType = cv2.MARKER_CROSS, thickness=3)\n",
    "    return vis\n",
    "\n",
    "def draw_marker_pts(vis_orig, pts, color = (255, 255, 0),markerSize=30):\n",
    "    vis = cv2.cvtColor(vis_orig,cv2.COLOR_GRAY2RGB)\n",
    "    for row in pts[:,0,:]:\n",
    "        cv2.drawMarker(vis, (int(row[0]), int(row[1])), color,  markerSize=markerSize, markerType = cv2.MARKER_CROSS, thickness=1)\n",
    "    return vis\n",
    "\n",
    "def draw_arrows(vis_orig, points1, points2, color = (0, 255, 0), thick = 1):\n",
    "    vis = cv2.cvtColor(vis_orig,cv2.COLOR_GRAY2RGB)\n",
    "    #rad = int(vis.shape[1]/200)\n",
    "    for p1,p2 in zip(points1,points2):\n",
    "        cv2.arrowedLine(vis, (int(p1[0]),int(p1[1])), (int(p2[0]),int(p2[1])), color=(0,255,0), thickness=thick)\n",
    "    return vis\n",
    "\n",
    "def draw_feature_tracks(img_left,kp1,img_right,kp2, matches, mask, display_invalid=False, color=(0, 255, 0)):\n",
    "    '''\n",
    "    This function extracts takes a 2 images, set of keypoints and a mask of valid\n",
    "    (mask as a ndarray) keypoints and plots the valid ones in green and invalid in red.\n",
    "    The mask should be the same length as matches\n",
    "    '''\n",
    "    if mask is None: bool_mask = np.ones((len(matches)), dtype=bool)\n",
    "    else: bool_mask = mask.astype(bool)\n",
    "    valid_right_matches = np.array([kp2[mat.trainIdx].pt for is_match, mat in zip(bool_mask, matches) if is_match])\n",
    "    valid_left_matches = np.array([kp1[mat.queryIdx].pt for is_match, mat in zip(bool_mask, matches) if is_match])\n",
    "    #img_right_out = draw_points(img_right, valid_right_matches)\n",
    "    img_right_out = draw_arrows(img_right, valid_left_matches, valid_right_matches)\n",
    "    return img_right_out\n",
    "\n",
    "def displayMatches(img_left,kp1,img_right,kp2, matches, mask, display_invalid, in_image=None, color=(0, 255, 0)):\n",
    "    '''\n",
    "    This function extracts takes a 2 images, set of keypoints and a mask of valid\n",
    "    (mask as a ndarray) keypoints and plots the valid ones in green and invalid in red.\n",
    "    The mask should be the same length as matches\n",
    "    '''\n",
    "    bool_mask = mask.astype(bool)\n",
    "    if in_image is None: mode_flag=0\n",
    "    else: mode_flag =1\n",
    "    img_valid = cv2.drawMatches(img_left,kp1,img_right,kp2,matches, in_image, \n",
    "                                matchColor=color, \n",
    "                                matchesMask=bool_mask.ravel().tolist(), flags=mode_flag)\n",
    "    \n",
    "    if display_invalid:\n",
    "        img_valid = cv2.drawMatches(img_left,kp1,img_right,kp2,matches, img_valid, \n",
    "                                  matchColor=(255, 0, 0), \n",
    "                                  matchesMask=np.invert(bool_mask).ravel().tolist(), \n",
    "                                  flags=1)\n",
    "    return img_valid\n",
    "\n",
    "\n",
    "K = np.array([[699.33112889, 0.0, 403.23876197],\n",
    "              [0.0, 693.66457792, 293.40739086],\n",
    "              [0.0, 0.0, 1.0]])\n",
    "\n",
    "D =  np.array([-2.78089511e-01,  1.30037134e-01, -1.17555797e-04, -1.55337290e-04, -4.34486330e-02])\n",
    "\n",
    "if sys.platform == 'darwin':\n",
    "    path = '/Users/vik748/Google Drive/'\n",
    "else:\n",
    "    path = '/home/vik748/'\n",
    "img1 = cv2.imread(path+'data/time_lapse_5_cervino_800x600/G0057821.png',1) # iscolor = CV_LOAD_IMAGE_GRAYSCALE\n",
    "img2 = cv2.imread(path+'data/time_lapse_5_cervino_800x600/G0057826.png',1) # iscolor = CV_LOAD_IMAGE_GRAYSCALE\n",
    "\n",
    "\n",
    "gr1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gr2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "'''\n",
    "clahe = cv2.createCLAHE(clipLimit=40.0, tileGridSize=(4,3))\n",
    "gr1 = clahe.apply(gr1)\n",
    "gr2 = clahe.apply(gr2)\n",
    "'''\n",
    "\n",
    "# create a mask image filled with 1s, the size of original image\n",
    "m1 = cv2.imread(path+'data/time_lapse_5_cervino_800x600_masks_out/G0056825_mask.png',cv2.IMREAD_GRAYSCALE)\n",
    "m2 = cv2.imread(path+'data/time_lapse_5_cervino_800x600_masks_out/G0057826_mask.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def radial_non_max(kp_list, dist):\n",
    "    kp = np.array(kp_list)\n",
    "    kp_mask = np.ones(len(kp), dtype=bool)\n",
    "    pts = [k.pt for k in kp]\n",
    "    tree = spatial.cKDTree(pts)\n",
    "    #print (\"len of kp1:\",len(kp))\n",
    "    for i, k in enumerate(kp):\n",
    "        if kp_mask[i]:\n",
    "            pt = tree.data[i]\n",
    "            idx = tree.query_ball_point(tree.data[i], dist, p=2., eps=0, n_jobs=1)\n",
    "            resp = [kp[ii].response for ii in idx]\n",
    "            _, maxi = max([(v,i) for i,v in enumerate(resp)])\n",
    "            del idx[maxi]\n",
    "            for kp_i in idx:\n",
    "                kp_mask[kp_i] = False \n",
    "    return kp[kp_mask].tolist()\n",
    "\n",
    "def bounding_box(points, min_x=-np.inf, max_x=np.inf, min_y=-np.inf,\n",
    "                        max_y=np.inf):\n",
    "    \"\"\" Compute a bounding_box filter on the given points\n",
    "\n",
    "    Parameters\n",
    "    ----------                        \n",
    "    points: (n,2) array\n",
    "        The array containing all the points's coordinates. Expected format:\n",
    "            array([\n",
    "                [x1,y1],\n",
    "                ...,\n",
    "                [xn,yn]])\n",
    "\n",
    "    min_i, max_i: float\n",
    "        The bounding box limits for each coordinate. If some limits are missing,\n",
    "        the default values are -infinite for the min_i and infinite for the max_i.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bb_filter : boolean array\n",
    "        The boolean mask indicating wherever a point should be keept or not.\n",
    "        The size of the boolean mask will be the same as the number of given points.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    bound_x = np.logical_and(points[:, 0] > min_x, points[:, 0] < max_x)\n",
    "    bound_y = np.logical_and(points[:, 1] > min_y, points[:, 1] < max_y)\n",
    "\n",
    "    bb_filter = np.logical_and(bound_x, bound_y)\n",
    "\n",
    "    return bb_filter\n",
    "\n",
    "\n",
    "def tiled_features(kp, img_shape, tiley, tilex):\n",
    "    feat_per_cell = int(len(kp)/(tilex*tiley))\n",
    "    HEIGHT, WIDTH = img_shape\n",
    "    assert WIDTH%tiley == 0, \"Width is not a multiple of tilex\"\n",
    "    assert HEIGHT%tilex == 0, \"Height is not a multiple of tiley\"\n",
    "    w_width = int(WIDTH/tiley)\n",
    "    w_height = int(HEIGHT/tilex)\n",
    "        \n",
    "    xx = np.linspace(0,HEIGHT-w_height,tilex,dtype='int')\n",
    "    yy = np.linspace(0,WIDTH-w_width,tiley,dtype='int')\n",
    "        \n",
    "    kps = np.array([])\n",
    "    pts = np.array([keypoint.pt for keypoint in kp])\n",
    "    kp = np.array(kp)\n",
    "    \n",
    "    for ix in xx:\n",
    "        for iy in yy:\n",
    "            inbox_mask = bounding_box(pts, iy,iy+w_height,ix,ix+w_height)\n",
    "            inbox = kp[inbox_mask]\n",
    "            inbox_sorted = sorted(inbox, key = lambda x:x.response, reverse = True)\n",
    "            inbox_sorted_out = inbox_sorted[:feat_per_cell]\n",
    "            kps = np.append(kps,inbox_sorted_out)\n",
    "    return kps.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TILE_KP = True\n",
    "RADIAL_NON_MAX = True\n",
    "RADIAL_NON_MAX_RADIUS = 5\n",
    "TILEY = 4\n",
    "TILEX = 3\n",
    "'''\n",
    "detector = cv2.ORB_create(nfeatures=10000, scaleFactor=2.0, nlevels=4, edgeThreshold=31, \n",
    "                           firstLevel=0, WTA_K=2, scoreType=cv2.ORB_HARRIS_SCORE,  \n",
    "                           patchSize=31, fastThreshold=15)\n",
    "'''\n",
    "detector = cv2.xfeatures2d.SIFT_create(nfeatures = 10000, nOctaveLayers = 3, contrastThreshold = 0.01, \n",
    "                                       edgeThreshold = 20, sigma = 1.6)\n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1 = detector.detect(gr1,m1)\n",
    "print(\"Detected kps: \",len(kp1))\n",
    "kp2 = detector.detect(gr2,m2)\n",
    "\n",
    "if TILE_KP:\n",
    "    kp1 = tiled_features(kp1, gr1.shape, TILEY, TILEX)\n",
    "    kp2 = tiled_features(kp2, gr2.shape, TILEY, TILEX)\n",
    "    print (\"Points after tiling supression: \",len(kp1))\n",
    "\n",
    "if RADIAL_NON_MAX:\n",
    "    kp1 = radial_non_max(kp1,RADIAL_NON_MAX_RADIUS)\n",
    "    kp2 = radial_non_max(kp2,RADIAL_NON_MAX_RADIUS)\n",
    "    print (\"Points after radial supression: \",len(kp1))\n",
    "\n",
    "img_out1 = draw_keypoints(cv2.cvtColor(gr1, cv2.COLOR_GRAY2BGR),kp1)\n",
    "img_out2 = draw_keypoints(cv2.cvtColor(gr2, cv2.COLOR_GRAY2BGR),kp2)\n",
    "\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1,2,dpi=200)\n",
    "fig.suptitle('800x600 Yellow circle defult setting patchSize=31')\n",
    "ax1.axis(\"off\")\n",
    "ax1.imshow(img_out1)\n",
    "ax2.axis(\"off\")\n",
    "ax2.imshow(img_out2)\n",
    "fig.subplots_adjust(0,0,1,1,0.0,0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kp1, des1 = detector.compute(gr1,kp1)\n",
    "#kp2, des2 = detector.compute(gr2,kp2)\n",
    "\n",
    "kp1z=[]\n",
    "des1z = np.zeros((len(kp1),25),dtype='float32')\n",
    "for i,k in enumerate(kp1):\n",
    "    mts = features.zernike_moments(gr1, 22, 8,cm=k.pt)\n",
    "    if mts.any():\n",
    "        des1z[i,:]=mts\n",
    "        kp1z += [k]\n",
    "des1z = des1z[:len(kp1z)]\n",
    "   \n",
    "kp2z=[]\n",
    "des2z = np.zeros((len(kp2),25),dtype='float32')\n",
    "for i,k in enumerate(kp2):\n",
    "    mts = features.zernike_moments(gr2, 22, 8,cm=k.pt)\n",
    "    if mts.any():\n",
    "        des2z[i,:]=mts\n",
    "        kp2z += [k]    \n",
    "des2z = des2z[:len(kp2z)]\n",
    "\n",
    "    \n",
    "'''\n",
    "FLANN_INDEX_LSH = 6\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "matcher = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_LSH, table_number = 6, key_size = 20,\n",
    "                                   multi_probe_level = 2), dict(checks=100))\n",
    "'''\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "#matches12_knn = matcher.knnMatch(des1,des2,k=2)\n",
    "matches12 = matcher.match(des1z,des2z)\n",
    "#matches12 = [item for sublist in matches12_knn for item in sublist]\n",
    "print(\"Found matches: \",len(matches12))\n",
    "\n",
    "kp1_match_12 = np.array([kp1z[mat.queryIdx].pt for mat in matches12])\n",
    "kp2_match_12 = np.array([kp2z[mat.trainIdx].pt for mat in matches12])\n",
    "\n",
    "#matches12 = sorted(matches12, key = lambda x:x.distance)\n",
    "#matches12 = matches12[:(int)(len(matches12)*.75)]\n",
    "\n",
    "kp1_match_12_ud = cv2.undistortPoints(np.expand_dims(kp1_match_12,axis=1),K,D)\n",
    "kp2_match_12_ud = cv2.undistortPoints(np.expand_dims(kp2_match_12,axis=1),K,D)\n",
    "\n",
    "E_12, mask_e_12 = cv2.findEssentialMat(kp1_match_12_ud, kp2_match_12_ud, focal=1.0, pp=(0., 0.), \n",
    "                                       method=cv2.RANSAC, prob=0.9999, threshold=0.001)\n",
    "\n",
    "print(\"After essential: \", np.sum(mask_e_12))\n",
    "\n",
    "#img_valid = draw_feature_tracks(gr1,kp1z,gr2,kp2z, matches12, mask_e_12, display_invalid=True, color=(0, 255, 0))\n",
    "img_valid = displayMatches(gr1,kp1,gr2,kp2, matches12, mask_e_12, display_invalid=True, color=(0, 255, 0))\n",
    "\n",
    "fig, ax= plt.subplots(dpi=200)\n",
    "plt.title('800x600 Yellow circle defult setting patchSize=31')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_valid)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    matches_knn = matcher.knnMatch(des1,des2, k=5)\n",
    "    matches = []\n",
    "    kp1_match = []\n",
    "    kp2_match = []\n",
    "    \n",
    "    for i,match in enumerate(matches_knn):\n",
    "        if len(match)>1:\n",
    "            if match[0].distance < 0.80*match[1].distance:\n",
    "                matches.append(match[0])\n",
    "                kp1_match.append(kp1[match[0].queryIdx].pt)\n",
    "                kp2_match.append(kp2[match[0].trainIdx].pt)\n",
    "        elif len(match)==1:\n",
    "            matches.append(match[0])\n",
    "            kp1_match.append(kp1[match[0].queryIdx].pt)\n",
    "            kp2_match.append(kp2[match[0].trainIdx].pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHarrisZernike (cv2.Feature2D):\n",
    "    def __init__(self, first, last, staffnum):\n",
    "        Person.__init__(self,first, last)\n",
    "        self.staffnumber = staffnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MultiHarrisZernike()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.detect(gr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "I = np.float64(gr1)\n",
    "\n",
    "dx = \n",
    "signal.convolve2d(dx,dx,'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.signal import convolve2d\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "def fspecial_gauss(size, sigma):\n",
    "    \"\"\"\n",
    "    Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g/g.sum()\n",
    "\n",
    "def harris(img, N_feat = 500, thresh = 0.0, tiling = (1,1), mask=None,\n",
    "           gsize = 3, gsigma = 0.5, local_maxima_nhood = 3):\n",
    "    '''\n",
    "    HARRIS Harris corner detector\n",
    "    This function implements a version of the Harris corner detector which\n",
    "    has the ability to calculate the eigenvalues of the gradient matrix\n",
    "    directly.  This is opposed to calculating the corner response function as\n",
    "    originally proposed by Harris in:\n",
    "    \n",
    "    C. Harris and M. Stephens.  \"A Combined Corner and Edge\n",
    "    Detector\", Proceedings of the 4th Alvey Vision Conference,\n",
    "    Manchester, U.K. pgs 147-151, 1988\n",
    "    \n",
    "    INPUT:\n",
    "    I is the graylevel image to extract interest points from\n",
    "    PARAMETER     DEFAULT   DESCRIPTION\n",
    "    ----------   --------  --------------------------\n",
    "    N_feat            500    maximum number of interest points to return\n",
    "    'thresh'          0    smallest acceptable value of response function\n",
    "    'gsize          3    size of the smoothing Gaussian mask\n",
    "    'gsigma         0.5   standard deviation of Gaussian filter\n",
    "    local_maxima_nhood\n",
    "    'tile'          [1 1]  break the image into regions [y x] to\n",
    "                           distribute feature points more uniformly\n",
    "    'mask'           M     array of 1's same size as image defining\n",
    "                           where to compute feature points (useful\n",
    "                           for radially compensated images)\n",
    "    \n",
    "    OUTPUT:\n",
    "    kps=(y,x) are the row/column locations of interest points\n",
    "    M is the corner response function value associated with that point\n",
    "    \n",
    "    Example:\n",
    "    I = cv2.imread('cameraman.tif');\n",
    "    [kps,M] = harris(I,500,tiling=(2,2))\n",
    "    '''\n",
    "    if len(img.shape) > 2:\n",
    "        raise ValueError('Image supplied is not grayscale')\n",
    "    \n",
    "    border = int(np.ceil(gsize/2))\n",
    "    mb = np.zeros_like(img)\n",
    "    mb[border:-border,border:-border]=1\n",
    "    if mask is None:\n",
    "        mask = mb\n",
    "    else:\n",
    "        mask = np.logical_and(mask,mb)\n",
    "        \n",
    "    I = np.float64(img)\n",
    "    (nr, nc) = I.shape\n",
    "    (tile_x, tile_y) = tiling\n",
    "\n",
    "    dx = np.array([[-1,0,1],[-1, 0, 1], [-1,0,1]])/3\n",
    "    dy = dx.T\n",
    "    \n",
    "    st = time.time()\n",
    "    Ix = convolve(I,dx,mode='nearest')\n",
    "    Iy = convolve(I,dy,mode='nearest')\n",
    "    #[Iy, Ix] = np.gradient(I,edge_order=1) - The way it was in Oscar's version\n",
    "\n",
    "    IxIx = np.square(Ix)\n",
    "    IyIy = np.square(Iy)\n",
    "    IxIy = Ix*Iy\n",
    "\n",
    "    gmask = fspecial_gauss(gsize, gsigma)\n",
    "    IxIx = convolve(IxIx,gmask,mode='nearest')\n",
    "    IyIy = convolve(IyIy,gmask,mode='nearest')\n",
    "    IxIy = convolve(IxIy,gmask,mode='nearest')\n",
    "    #print(\"elapsde =\",time.time()-st )\n",
    "\n",
    "    B = IxIx + IyIy\n",
    "    SQRTRM = np.sqrt(np.square(B) - 4*(IxIx*IyIy-np.square(IxIy)))\n",
    "    lambda1 = (B+SQRTRM)/2\n",
    "    lambda2 = (B-SQRTRM)/2\n",
    "    R = lambda1*lambda2 - 0.04*np.square(lambda1+lambda2)\n",
    "    Maxima = (np.logical_and(maximum_filter(R,size=local_maxima_nhood)<=R, mask)) * R  # add mask here...\n",
    "    (i,j) = np.nonzero(Maxima > thresh)\n",
    "    m = Maxima[i,j]\n",
    "    sidx = np.argsort(-m) # Sorted indexes\n",
    "    m = m[sidx]\n",
    "    i = i[sidx]\n",
    "    j = j[sidx]\n",
    "\n",
    "    w_width = int(nc/tile_x)\n",
    "    w_height = int(nr/tile_y)\n",
    "\n",
    "    if tile_x > 1 and tile_y > 1:\n",
    "        if nc % tile_x >0 or nr % tile_y>0:\n",
    "            raise ValueError('Image size not a multiple of specified tiling')\n",
    "        Npts_per_region = int(np.round(N_feat/(tile_x*tile_y)))\n",
    "        # process image regionally so that corners are uniformally\n",
    "        # extracted across image regions\n",
    "        ii = np.array([],dtype=int)\n",
    "        jj = np.array([],dtype=int)     \n",
    "        mm = np.array([],dtype=float)\n",
    "        xx = np.round(np.linspace(0,nc,tile_x+1)) # region boundaries\n",
    "        yy = np.round(np.linspace(0,nr,tile_y+1))\n",
    "        for xll,xul in zip(xx[:-1],xx[1:]):\n",
    "            # points falling within the region's x boundaries\n",
    "            maskx = np.logical_and(j >= xll, j < xul)\n",
    "            for yll,yul in zip(yy[:-1],yy[1:]):\n",
    "                # points falling within the region's y boundaries\n",
    "                masky = np.logical_and(i >= yll, i < yul)\n",
    "\n",
    "                # their common intersection\n",
    "                maskxy = np.logical_and(maskx, masky)\n",
    "                id = np.argwhere(maskxy)\n",
    "                sel_pts = id[0:Npts_per_region]\n",
    "                #print(id)\n",
    "                # return the strongest N points as defined by user\n",
    "                #print (id[0:Npts_per_region])\n",
    "                ii = np.append(ii, i[sel_pts])\n",
    "                jj = np.append(jj, j[sel_pts])\n",
    "                mm = np.append(mm, m[sel_pts])      \n",
    "    else:\n",
    "        ii = i[0:N_feat]\n",
    "        jj = j[0:N_feat]\n",
    "        mm = m[0:N_feat]\n",
    "    return np.vstack((jj,ii)).T,mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gi = fspecial_gauss(11, 2.75)\n",
    "lpf = P.lpimages[0]\n",
    "scale = 0.75\n",
    "[eig, nL] = eigen_image_p(lpf,Gi,scale)\n",
    "fig, [ax1,ax2] = plt.subplots(2,1,dpi=200)\n",
    "fig.suptitle('eig and nL images')\n",
    "#a.axis(\"off\")\n",
    "ax1.imshow(eig,cmap='gray'),ax1.axis(\"off\")\n",
    "ax2.imshow(nL,cmap='gray'),ax2.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "for i in range(10):\n",
    "    kps, M = harris(gr1, N_feat = 500, thresh = 0.0, tiling = (8,6), mask=None,\n",
    "               gsize = 3, gsigma = 0.5, local_maxima_nhood = 3)\n",
    "print(\"elapsed: \",(time.time()-st)/10)\n",
    "imgout = draw_marker_pts(gr1, np.expand_dims(kps,axis=1),markerSize=10)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1,dpi=200)\n",
    "plt.title('800x600 Yellow circle defult setting patchSize=31')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgout)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigen_image_p(lpf,Gi,scale):\n",
    "    '''    \n",
    "    %function [ef2,nL] = eigen_image_p(lpf,Gi)\n",
    "    %set up in pyramid scheme with detection scaled smoothed images\n",
    "    %ef2 is the interest point eigen image\n",
    "    %lpf smoothed by the detection scale gaussian\n",
    "    %Gi = fspecial('gaussian',ceil(7*sigi),sigi);\n",
    "    '''\n",
    "    [fy,fx] = np.gradient(lpf)\n",
    "\n",
    "    [fxy,fxx] = np.gradient(fx)\n",
    "    [fyy,fyx] = np.gradient(fy)\n",
    "    nL = scale**(-2)*np.abs(fxx+fyy)\n",
    "\n",
    "    Mfxx = convolve(np.square(fx),Gi,mode='constant')\n",
    "    Mfxy = convolve(fx*fy,Gi,mode='constant')\n",
    "    Mfyy = convolve(np.square(fy),Gi,mode='constant')\n",
    "\n",
    "    Tr = Mfxx+Mfyy\n",
    "    Det = Mfxx*Mfyy-np.square(Mfxy)\n",
    "    sqrterm = np.sqrt(np.square(Tr)-4*Det)\n",
    "\n",
    "    ef2 = scale**(-2)*0.5*(Tr - sqrterm)\n",
    "    return ef2,nL\n",
    "\n",
    "class ImagePyramid:\n",
    "    def __init__ (self, levels, ratio, sigdec, sigint):\n",
    "        self.levels = levels\n",
    "        self.ratio = ratio\n",
    "        self.images = []\n",
    "        self.lpimages = []\n",
    "        self.sigd = [sigdec]\n",
    "        self.sigi = [sigint]\n",
    "        self.lpfilter = fspecial_gauss(int(np.ceil(7*sigdec)),sigdec)\n",
    "        # Make a note of this 7x7 gaussian kernel, lowering will speed up computation\n",
    "        \n",
    "    def generate_pyramid(self,img):\n",
    "        self.images = [np.float64(img)]\n",
    "        self.lpimages = [convolve(self.images[0],self.lpfilter,mode='constant')]\n",
    "        for k in range(1,self.levels):\n",
    "            self.images += [cv2.resize(self.lpimages[-1], (0,0), fx=self.ratio,\n",
    "                                      fy=self.ratio, interpolation=cv2.INTER_LINEAR)]\n",
    "            self.lpimages += [convolve(self.images[-1],self.lpfilter,mode='nearest')]\n",
    "            self.sigd += [self.sigd[-1]/self.ratio] #equivalent sigdec at max res\n",
    "            self.sigi += [self.sigi[-1]/self.ratio] \n",
    "\n",
    "            \n",
    "P = ImagePyramid(6,0.75,1,2.75)\n",
    "st = time.time()\n",
    "for i in range(10):\n",
    "    P.generate_pyramid(gr1)\n",
    "print(\"time: \",(time.time()-st)/10)\n",
    "fig, ax1 = plt.subplots(1,1,dpi=200)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(P.lpimages[3],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = ImagePyramid(6,0.75,1,2.75)\n",
    "P.generate_pyramid(gr1)\n",
    "zrad = 22\n",
    "Gi = fspecial_gauss(11, 2.75)\n",
    "local_maxima_nhood=3\n",
    "\n",
    "scales = P.levels\n",
    "ratio = P.ratio\n",
    "#E(1).levels = scales;\n",
    "border = zrad\n",
    "[rows,cols] = P.lpimages[0].shape\n",
    "\n",
    "eig = [None] * scales\n",
    "nL = [None] * scales\n",
    "border_mask = [None] * scales \n",
    "regmask=[None] * scales \n",
    "ivec= [None] * scales \n",
    "jvec= [None] * scales\n",
    "\n",
    "for k in range(scales):\n",
    "    [eig[k], nL[k]] = eigen_image_p(P.lpimages[k] , Gi,ratio**(k))\n",
    "    # extract regional max and block out borders (edge effect)\n",
    "\n",
    "    # generate mask for border\n",
    "    border_mask[k] = np.zeros_like(eig[k],dtype=bool)\n",
    "    border_mask[k][border:-border,border:-border]=True\n",
    "\n",
    "    #E(k).regmask = imregionalmax(E(k).eig)\n",
    "    regmask[k] = maximum_filter(eig[k],size=local_maxima_nhood)<=eig[k]\n",
    "\n",
    "    regmask[k] = np.logical_and(regmask[k],border_mask[k])\n",
    "\n",
    "    #[ivec[k], jvec[k]] = np.nonzero(regmask[k]) #coordinates of 1s in regmask\n",
    "    # Just to match matlab version, can be reverted to optimise\n",
    "    [jvec[k], ivec[k]] = np.nonzero(regmask[k].T)\n",
    "    \n",
    "# INITIALIZE feature positions and scales at highest level\n",
    "# at highest resolution coordinates of features:\n",
    "Fivec = ivec[0]\n",
    "Fjvec = jvec[0]\n",
    "Fsvec = np.ones_like(Fivec) #initial scale \n",
    "Fevec = eig[0][ivec[0],jvec[0]] #access the elements of eig at locations given by ivec,jvec\n",
    "\n",
    "#i,j position of feature at the characteristic scale\n",
    "Fsivec = Fivec \n",
    "Fsjvec = Fjvec\n",
    "\n",
    "nLvec = nL[0][ivec[0],jvec[0]]\n",
    "pivec = Fivec\n",
    "pjvec = Fjvec\n",
    "pind = np.array(list(range(len(Fivec))))\n",
    "k = 1\n",
    "\n",
    "mx = (np.floor(cols*ratio)-1)/(cols-1)  #scale conversion to next level\n",
    "my = (np.floor(rows*ratio)-1)/(rows-1) \n",
    "\n",
    "[rows,cols]  = eig[k].shape #dimensions of next level\n",
    "pendreg = np.zeros_like(pivec)\n",
    "#sivec = np.round((pivec-1)*my+1).astype(int) #next scale ivec\n",
    "#sjvec = np.round((pjvec-1)*mx+1).astype(int) #next scale jvec\n",
    "# match matlab output\n",
    "sivec = np.round(pivec*my).astype(int) #next scale ivec\n",
    "sjvec = np.round(pjvec*mx).astype(int) #next scale jvec\n",
    "\n",
    "csivec = sivec\n",
    "csjvec = sjvec\n",
    "cloc = sivec+1 + rows*(sjvec)\n",
    "'''\n",
    "for u in range(-1,2):  #account for motion of feature points between scales\n",
    "        for v = in range(-1,2):\n",
    "\n",
    "        soivec = sivec+v; %next scale ivec\n",
    "        sojvec = sjvec+u; %next scale jvec\n",
    "\n",
    "        loc = soivec + rows*(sojvec-1); #index vector of next level\n",
    "        #have to account for motion of feature point at different\n",
    "        #scales - more than just the sampling\n",
    "\n",
    "        uvpend = E(k).regmask(loc) == 1;\n",
    "        pendreg = pendreg | uvpend;\n",
    "\n",
    "        cloc(uvpend) = loc(uvpend);\n",
    "        csivec(uvpend) = soivec(uvpend);\n",
    "        csjvec(uvpend) = sojvec(uvpend);\n",
    "\n",
    "pend = pendreg & (E(k).nL(cloc) >= nLvec);\n",
    "\n",
    "pind = pind(pend);\n",
    "\n",
    "F.svec(pind) = k; %scale is k or larger\n",
    "F.evec(pind) = E(k).eig(cloc(pend)); %eigen value is given at\n",
    "                                     %level k or larger\n",
    "F.sivec(pind) = csivec(pend);\n",
    "F.sjvec(pind) = csjvec(pend);\n",
    "\n",
    "pivec = csivec(pend);\n",
    "pjvec = csjvec(pend);\n",
    "nLvec = E(k).nL(cloc(pend));\n",
    "k = k+1;\n",
    "'''     \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sivec[-10:])\n",
    "print (sjvec[-10:])\n",
    "print (cloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows*(sjvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fevec[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jvec[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fevec = eig[0](ivec[0] + rows*(jvec[0]-1)) #1D index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((6,6))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.array([2,3,4,5]);\n",
    "j = np.array([1,2,3,4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slam_env",
   "language": "python",
   "name": "slam_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

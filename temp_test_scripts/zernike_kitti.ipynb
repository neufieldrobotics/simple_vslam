{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Zernike Test\n",
    "## Setup the required functions and input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb  1 20:06:06 2019\n",
    "\n",
    "@author: vik748\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from zernike import MultiHarrisZernike\n",
    "from vslam_helper import *\n",
    "\n",
    "def draw_keypoints(vis_orig, keypoints, color = (255, 255, 0), thick = 1):\n",
    "    vis = vis_orig.copy()\n",
    "    for kp in keypoints:\n",
    "        x, y = kp.pt\n",
    "        cv2.circle(vis, (int(x), int(y)), int(vis.shape[1]/200), color, thickness=thick)\n",
    "    return vis\n",
    "\n",
    "def draw_markers(vis_orig, keypoints, color = (0, 0, 255)):\n",
    "    vis = vis_orig.copy()\n",
    "    for kp in keypoints:\n",
    "        x, y = kp.pt\n",
    "        cv2.drawMarker(vis, (int(x), int(y)), color,  markerSize=30, markerType = cv2.MARKER_CROSS, thickness=3)\n",
    "    return vis\n",
    "\n",
    "def draw_marker_pts(vis_orig, pts, color = (0, 0, 255)):\n",
    "    vis = vis_orig.copy()\n",
    "    for row in pts[:,0,:]:\n",
    "        cv2.drawMarker(vis, (int(row[0]), int(row[1])), color,  markerSize=30, markerType = cv2.MARKER_CROSS, thickness=3)\n",
    "    return vis\n",
    "\n",
    "def draw_arrows(vis_orig, points1, points2, color = (0, 255, 0), thick = 2):\n",
    "    vis = cv2.cvtColor(vis_orig,cv2.COLOR_GRAY2RGB)\n",
    "    #rad = int(vis.shape[1]/200)\n",
    "    for p1,p2 in zip(points1,points2):\n",
    "        cv2.arrowedLine(vis, (int(p1[0]),int(p1[1])), (int(p2[0]),int(p2[1])), color=(0,255,0), thickness=thick)\n",
    "    return vis\n",
    "\n",
    "def draw_feature_tracks(img_left,kp1,img_right,kp2, matches, mask, display_invalid=False, color=(0, 255, 0)):\n",
    "    '''\n",
    "    This function extracts takes a 2 images, set of keypoints and a mask of valid\n",
    "    (mask as a ndarray) keypoints and plots the valid ones in green and invalid in red.\n",
    "    The mask should be the same length as matches\n",
    "    '''\n",
    "    if mask is None: bool_mask = np.ones((len(matches)), dtype=bool)\n",
    "    else: bool_mask = mask.astype(bool)\n",
    "    valid_right_matches = np.array([kp2[mat.trainIdx].pt for is_match, mat in zip(bool_mask, matches) if is_match])\n",
    "    valid_left_matches = np.array([kp1[mat.queryIdx].pt for is_match, mat in zip(bool_mask, matches) if is_match])\n",
    "    #img_right_out = draw_points(img_right, valid_right_matches)\n",
    "    img_right_out = draw_arrows(img_right, valid_left_matches, valid_right_matches)\n",
    "    return img_right_out\n",
    "\n",
    "def displayMatches(img_left,kp1,img_right,kp2, matches, mask, display_invalid, in_image=None, color=(0, 255, 0)):\n",
    "    '''\n",
    "    This function extracts takes a 2 images, set of keypoints and a mask of valid\n",
    "    (mask as a ndarray) keypoints and plots the valid ones in green and invalid in red.\n",
    "    The mask should be the same length as matches\n",
    "    '''\n",
    "    bool_mask = mask.astype(bool)\n",
    "    if in_image is None: mode_flag=0\n",
    "    else: mode_flag =1\n",
    "    img_valid = cv2.drawMatches(img_left,kp1,img_right,kp2,matches, in_image, \n",
    "                                matchColor=color, \n",
    "                                matchesMask=bool_mask.ravel().tolist(), flags=mode_flag)\n",
    "    \n",
    "    if display_invalid:\n",
    "        img_valid = cv2.drawMatches(img_left,kp1,img_right,kp2,matches, img_valid, \n",
    "                                  matchColor=(255, 0, 0), \n",
    "                                  matchesMask=np.invert(bool_mask).ravel().tolist(), \n",
    "                                  flags=1)\n",
    "    return img_valid\n",
    "\n",
    "\n",
    "K = np.array([[718.856, 0.0, 607.1928],\n",
    "              [0.0, 718.856, 185.2157],\n",
    "              [0.0, 0.0, 1.0]])\n",
    "\n",
    "D =  np.array([0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "if sys.platform == 'darwin':\n",
    "    path = '/Users/vik748/Google Drive/'\n",
    "else:\n",
    "    path = '/home/vik748/'\n",
    "img1 = cv2.imread(path+'data/kitti/00/image_0/000001.png',0) # iscolor = CV_LOAD_IMAGE_GRAYSCALE\n",
    "img2 = cv2.imread(path+'data/kitti/00/image_0/000003.png',0) # iscolor = CV_LOAD_IMAGE_GRAYSCALE\n",
    "\n",
    "#gr1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "#gr2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "gr1 = img1\n",
    "gr2 = img2\n",
    "\n",
    "# create a mask image filled with 1s, the size of original image\n",
    "#m1 = cv2.imread(path+'data/time_lapse_5_cervino_800x600_masks_out/G0057821_mask.png',cv2.IMREAD_GRAYSCALE)\n",
    "#m2 = cv2.imread(path+'data/time_lapse_5_cervino_800x600_masks_out/G0057826_mask.png',cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detector = cv2.ORB_create(nfeatures=600, scaleFactor=2.0, nlevels=4, edgeThreshold=31, \n",
    "                           firstLevel=0, WTA_K=2, scoreType=cv2.ORB_HARRIS_SCORE,  \n",
    "                           patchSize=31, fastThreshold=15)\n",
    "'''\n",
    "detector = MultiHarrisZernike(Nfeats=600)\n",
    "'''\n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1,des1 = detector.detectAndCompute(gr1,None)\n",
    "kp2,des2 = detector.detectAndCompute(gr2,None)\n",
    "print(\"Detected kps1: \",len(kp1),\" kp2: \",len(kp2))\n",
    "\n",
    "kp1_top = sorted(kp1, key = lambda x:x.response)[-25:]\n",
    "kp2_top = sorted(kp2, key = lambda x:x.response)[-25:]\n",
    "\n",
    "img_out1 = cv2.drawKeypoints(gr1, kp1_top, gr1,color=[255,255,0],\n",
    "                             flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "img_out2 = cv2.drawKeypoints(gr2, kp2_top, gr2,color=[255,255,0],\n",
    "                             flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1,2,dpi=200)\n",
    "fig.suptitle('800x600 Yellow circle defult setting patchSize=31')\n",
    "ax1.axis(\"off\")\n",
    "ax1.imshow(img_out1)\n",
    "ax2.axis(\"off\")\n",
    "ax2.imshow(img_out2)\n",
    "fig.subplots_adjust(0,0,1,1,0.0,0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "matcher = cv2.FlannBasedMatcher(dict(algorithm = FLANN_INDEX_KDTREE, trees = 4), dict(checks=32) )\n",
    "'''\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "\n",
    "matches_12 = knn_match_and_lowe_ratio_filter(matcher, des1, des2, threshold=0.9)\n",
    "track_output = track_keypoints(kp1, des1, kp2, des2, matches_12)\n",
    "kp1_matched, des1_matched, kp2_matched, des2_matched, kp2_cand, des2_cand = track_output\n",
    "print(\"Found matches: \",len(matches_12))\n",
    "\n",
    "kp1_match_12 = np.expand_dims(np.array([o.pt for o in kp1_matched],dtype=np.float32),1)\n",
    "kp2_match_12 = np.expand_dims(np.array([o.pt for o in kp2_matched],dtype=np.float32),1)\n",
    "\n",
    "kp1_match_12_ud = cv2.undistortPoints(kp1_match_12,K,D)\n",
    "kp2_match_12_ud = cv2.undistortPoints(kp2_match_12,K,D)\n",
    "\n",
    "E_12, mask_e_12 = cv2.findEssentialMat(kp1_match_12_ud, kp2_match_12_ud, focal=1.0, pp=(0., 0.), \n",
    "                                       method=cv2.RANSAC, prob=0.9999, threshold=0.001)\n",
    "\n",
    "print(\"After essential: \", np.sum(mask_e_12))\n",
    "\n",
    "points, R_21, t_21, mask_RP_12 = cv2.recoverPose(E_12, kp1_match_12_ud, kp2_match_12_ud,mask=mask_e_12)\n",
    "print(\"After RP: \", np.sum(mask_RP_12))\n",
    "img_valid = draw_feature_tracks(gr1,kp1,gr2,kp2, matches_12, mask_RP_12, display_invalid=True, color=(0, 255, 0))\n",
    "#img_valid = displayMatches(gr1,kp1,gr2,kp2, matches_12, mask_e_12, display_invalid=False, color=(0, 255, 0))\n",
    "\n",
    "fig, ax= plt.subplots(dpi=200)\n",
    "plt.title('800x600 Zernike Matches after using findEssential mask')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_valid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_valid = displayMatches(gr1,kp1,gr2,kp2, matches, None, display_invalid=False, color=(0, 255, 0))\n",
    "img_valid = cv2.drawMatches(gr1,kp1,gr2,kp2,matches, None, flags=0)\n",
    "fig, ax= plt.subplots(dpi=200)\n",
    "plt.title('800x600 Yellow circle defult setting patchSize=31')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_valid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = kp1[0]\n",
    "import copy\n",
    "kp_copy = copy.deepcopy(kp1)\n",
    "p_copy = copy.deepcopy(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_copy[0].pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slam_kernel",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # scaled_harris_and_zernike_development \n",
    "## Setup the required functions and input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb  1 20:06:06 2019\n",
    "\n",
    "@author: vik748\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from ssc import *\n",
    "%matplotlib inline\n",
    "from scipy import spatial\n",
    "import time\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "\n",
    "#from mahotas import features\n",
    "\n",
    "def draw_keypoints(vis_orig, keypoints, color = (255, 255, 0), thick = 1):\n",
    "    vis = vis_orig.copy()\n",
    "    for kp in keypoints:\n",
    "        x, y = kp.pt\n",
    "        cv2.circle(vis, (int(x), int(y)), int(vis.shape[1]/200), color, thickness=thick)\n",
    "    return vis\n",
    "\n",
    "def draw_markers(vis_orig, keypoints, color = (0, 0, 255)):\n",
    "    vis = vis_orig.copy()\n",
    "    for kp in keypoints:\n",
    "        x, y = kp.pt\n",
    "        cv2.drawMarker(vis, (int(x), int(y)), color,  markerSize=30, markerType = cv2.MARKER_CROSS, thickness=3)\n",
    "    return vis\n",
    "\n",
    "def draw_marker_pts(vis_orig, pts, color = (255, 255, 0),markerSize=30):\n",
    "    vis = cv2.cvtColor(vis_orig,cv2.COLOR_GRAY2RGB)\n",
    "    for row in pts[:,0,:]:\n",
    "        cv2.drawMarker(vis, (int(row[0]), int(row[1])), color,  markerSize=markerSize, markerType = cv2.MARKER_CROSS, thickness=1)\n",
    "    return vis\n",
    "\n",
    "def draw_arrows(vis_orig, points1, points2, color = (0, 255, 0), thick = 1):\n",
    "    vis = cv2.cvtColor(vis_orig,cv2.COLOR_GRAY2RGB)\n",
    "    #rad = int(vis.shape[1]/200)\n",
    "    for p1,p2 in zip(points1,points2):\n",
    "        cv2.arrowedLine(vis, (int(p1[0]),int(p1[1])), (int(p2[0]),int(p2[1])), color=(0,255,0), thickness=thick)\n",
    "    return vis\n",
    "\n",
    "def draw_feature_tracks(img_left,kp1,img_right,kp2, matches, mask, display_invalid=False, color=(0, 255, 0)):\n",
    "    '''\n",
    "    This function extracts takes a 2 images, set of keypoints and a mask of valid\n",
    "    (mask as a ndarray) keypoints and plots the valid ones in green and invalid in red.\n",
    "    The mask should be the same length as matches\n",
    "    '''\n",
    "    if mask is None: bool_mask = np.ones((len(matches)), dtype=bool)\n",
    "    else: bool_mask = mask.astype(bool)\n",
    "    valid_right_matches = np.array([kp2[mat.trainIdx].pt for is_match, mat in zip(bool_mask, matches) if is_match])\n",
    "    valid_left_matches = np.array([kp1[mat.queryIdx].pt for is_match, mat in zip(bool_mask, matches) if is_match])\n",
    "    #img_right_out = draw_points(img_right, valid_right_matches)\n",
    "    img_right_out = draw_arrows(img_right, valid_left_matches, valid_right_matches)\n",
    "    return img_right_out\n",
    "\n",
    "def displayMatches(img_left,kp1,img_right,kp2, matches, mask, display_invalid, in_image=None, color=(0, 255, 0)):\n",
    "    '''\n",
    "    This function extracts takes a 2 images, set of keypoints and a mask of valid\n",
    "    (mask as a ndarray) keypoints and plots the valid ones in green and invalid in red.\n",
    "    The mask should be the same length as matches\n",
    "    '''\n",
    "    bool_mask = mask.astype(bool)\n",
    "    if in_image is None: mode_flag=0\n",
    "    else: mode_flag =1\n",
    "    img_valid = cv2.drawMatches(img_left,kp1,img_right,kp2,matches, in_image, \n",
    "                                matchColor=color, \n",
    "                                matchesMask=bool_mask.ravel().tolist(), flags=mode_flag)\n",
    "    \n",
    "    if display_invalid:\n",
    "        img_valid = cv2.drawMatches(img_left,kp1,img_right,kp2,matches, img_valid, \n",
    "                                  matchColor=(255, 0, 0), \n",
    "                                  matchesMask=np.invert(bool_mask).ravel().tolist(), \n",
    "                                  flags=1)\n",
    "    return img_valid\n",
    "\n",
    "\n",
    "K = np.array([[699.33112889, 0.0, 403.23876197],\n",
    "              [0.0, 693.66457792, 293.40739086],\n",
    "              [0.0, 0.0, 1.0]])\n",
    "\n",
    "D =  np.array([-2.78089511e-01,  1.30037134e-01, -1.17555797e-04, -1.55337290e-04, -4.34486330e-02])\n",
    "\n",
    "if sys.platform == 'darwin':\n",
    "    path = '/Users/vik748/Google Drive/'\n",
    "else:\n",
    "    path = '/home/vik748/'\n",
    "img1 = cv2.imread(path+'data/time_lapse_5_cervino_800x600/G0057821.png',1) # iscolor = CV_LOAD_IMAGE_GRAYSCALE\n",
    "img2 = cv2.imread(path+'data/time_lapse_5_cervino_800x600/G0057826.png',1) # iscolor = CV_LOAD_IMAGE_GRAYSCALE\n",
    "\n",
    "\n",
    "gr1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gr2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "'''\n",
    "clahe = cv2.createCLAHE(clipLimit=40.0, tileGridSize=(4,3))\n",
    "gr1 = clahe.apply(gr1)\n",
    "gr2 = clahe.apply(gr2)\n",
    "'''\n",
    "\n",
    "# create a mask image filled with 1s, the size of original image\n",
    "m1 = cv2.imread(path+'data/time_lapse_5_cervino_800x600_masks_out/G0056825_mask.png',cv2.IMREAD_GRAYSCALE)\n",
    "m2 = cv2.imread(path+'data/time_lapse_5_cervino_800x600_masks_out/G0057826_mask.png',cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHarrisZernike (cv2.Feature2D):\n",
    "    def __init__(self, first, last, staffnum):\n",
    "        Person.__init__(self,first, last)\n",
    "        self.staffnumber = staffnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MultiHarrisZernike()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.detect(gr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.signal import convolve2d\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage import convolve\n",
    "import matlab_imresize.imresize\n",
    "\n",
    "def fspecial_gauss(size, sigma):\n",
    "    \"\"\"\n",
    "    Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g/g.sum()\n",
    "\n",
    "def harris(img, N_feat = 500, thresh = 0.0, tiling = (1,1), mask=None,\n",
    "           gsize = 3, gsigma = 0.5, local_maxima_nhood = 3):\n",
    "    '''\n",
    "    HARRIS Harris corner detector\n",
    "    This function implements a version of the Harris corner detector which\n",
    "    has the ability to calculate the eigenvalues of the gradient matrix\n",
    "    directly.  This is opposed to calculating the corner response function as\n",
    "    originally proposed by Harris in:\n",
    "    \n",
    "    C. Harris and M. Stephens.  \"A Combined Corner and Edge\n",
    "    Detector\", Proceedings of the 4th Alvey Vision Conference,\n",
    "    Manchester, U.K. pgs 147-151, 1988\n",
    "    \n",
    "    INPUT:\n",
    "    I is the graylevel image to extract interest points from\n",
    "    PARAMETER     DEFAULT   DESCRIPTION\n",
    "    ----------   --------  --------------------------\n",
    "    N_feat            500    maximum number of interest points to return\n",
    "    'thresh'          0    smallest acceptable value of response function\n",
    "    'gsize          3    size of the smoothing Gaussian mask\n",
    "    'gsigma         0.5   standard deviation of Gaussian filter\n",
    "    local_maxima_nhood\n",
    "    'tile'          [1 1]  break the image into regions [y x] to\n",
    "                           distribute feature points more uniformly\n",
    "    'mask'           M     array of 1's same size as image defining\n",
    "                           where to compute feature points (useful\n",
    "                           for radially compensated images)\n",
    "    \n",
    "    OUTPUT:\n",
    "    kps=(y,x) are the row/column locations of interest points\n",
    "    M is the corner response function value associated with that point\n",
    "    \n",
    "    Example:\n",
    "    I = cv2.imread('cameraman.tif');\n",
    "    [kps,M] = harris(I,500,tiling=(2,2))\n",
    "    '''\n",
    "    if len(img.shape) > 2:\n",
    "        raise ValueError('Image supplied is not grayscale')\n",
    "    \n",
    "    border = int(np.ceil(gsize/2))\n",
    "    mb = np.zeros_like(img)\n",
    "    mb[border:-border,border:-border]=1\n",
    "    if mask is None:\n",
    "        mask = mb\n",
    "    else:\n",
    "        mask = np.logical_and(mask,mb)\n",
    "        \n",
    "    I = np.float64(img)\n",
    "    (nr, nc) = I.shape\n",
    "    (tile_x, tile_y) = tiling\n",
    "\n",
    "    dx = np.array([[-1,0,1],[-1, 0, 1], [-1,0,1]])/3\n",
    "    dy = dx.T\n",
    "    \n",
    "    st = time.time()\n",
    "    Ix = convolve(I,dx,mode='nearest')\n",
    "    Iy = convolve(I,dy,mode='nearest')\n",
    "    #[Iy, Ix] = np.gradient(I,edge_order=1) - The way it was in Oscar's version\n",
    "\n",
    "    IxIx = np.square(Ix)\n",
    "    IyIy = np.square(Iy)\n",
    "    IxIy = Ix*Iy\n",
    "\n",
    "    gmask = fspecial_gauss(gsize, gsigma)\n",
    "    IxIx = convolve(IxIx,gmask,mode='nearest')\n",
    "    IyIy = convolve(IyIy,gmask,mode='nearest')\n",
    "    IxIy = convolve(IxIy,gmask,mode='nearest')\n",
    "    #print(\"elapsde =\",time.time()-st )\n",
    "\n",
    "    B = IxIx + IyIy\n",
    "    SQRTRM = np.sqrt(np.square(B) - 4*(IxIx*IyIy-np.square(IxIy)))\n",
    "    lambda1 = (B+SQRTRM)/2\n",
    "    lambda2 = (B-SQRTRM)/2\n",
    "    R = lambda1*lambda2 - 0.04*np.square(lambda1+lambda2)\n",
    "    Maxima = (np.logical_and(maximum_filter(R,size=local_maxima_nhood)<=R, mask)) * R  # add mask here...\n",
    "    (i,j) = np.nonzero(Maxima > thresh)\n",
    "    m = Maxima[i,j]\n",
    "    sidx = np.argsort(-m) # Sorted indexes\n",
    "    m = m[sidx]\n",
    "    i = i[sidx]\n",
    "    j = j[sidx]\n",
    "\n",
    "    w_width = int(nc/tile_x)\n",
    "    w_height = int(nr/tile_y)\n",
    "\n",
    "    if tile_x > 1 and tile_y > 1:\n",
    "        if nc % tile_x >0 or nr % tile_y>0:\n",
    "            raise ValueError('Image size not a multiple of specified tiling')\n",
    "        Npts_per_region = int(np.round(N_feat/(tile_x*tile_y)))\n",
    "        # process image regionally so that corners are uniformally\n",
    "        # extracted across image regions\n",
    "        ii = np.array([],dtype=int)\n",
    "        jj = np.array([],dtype=int)     \n",
    "        mm = np.array([],dtype=float)\n",
    "        xx = np.round(np.linspace(0,nc,tile_x+1)) # region boundaries\n",
    "        yy = np.round(np.linspace(0,nr,tile_y+1))\n",
    "        for xll,xul in zip(xx[:-1],xx[1:]):\n",
    "            # points falling within the region's x boundaries\n",
    "            maskx = np.logical_and(j >= xll, j < xul)\n",
    "            for yll,yul in zip(yy[:-1],yy[1:]):\n",
    "                # points falling within the region's y boundaries\n",
    "                masky = np.logical_and(i >= yll, i < yul)\n",
    "\n",
    "                # their common intersection\n",
    "                maskxy = np.logical_and(maskx, masky)\n",
    "                id = np.argwhere(maskxy)\n",
    "                sel_pts = id[0:Npts_per_region]\n",
    "                #print(id)\n",
    "                # return the strongest N points as defined by user\n",
    "                #print (id[0:Npts_per_region])\n",
    "                ii = np.append(ii, i[sel_pts])\n",
    "                jj = np.append(jj, j[sel_pts])\n",
    "                mm = np.append(mm, m[sel_pts])      \n",
    "    else:\n",
    "        ii = i[0:N_feat]\n",
    "        jj = j[0:N_feat]\n",
    "        mm = m[0:N_feat]\n",
    "    return np.vstack((jj,ii)).T,mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "for i in range(10):\n",
    "    kps, M = harris(gr1, N_feat = 500, thresh = 0.0, tiling = (8,6), mask=None,\n",
    "               gsize = 3, gsigma = 0.5, local_maxima_nhood = 3)\n",
    "print(\"elapsed: \",(time.time()-st)/10)\n",
    "imgout = draw_marker_pts(gr1, np.expand_dims(kps,axis=1),markerSize=10)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1,dpi=200)\n",
    "plt.title('800x600 Yellow circle defult setting patchSize=31')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgout)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matlab_imresize.imresize import imresize\n",
    "\n",
    "def eigen_image_p(lpf,Gi,scale):\n",
    "    '''    \n",
    "    %function [ef2,nL] = eigen_image_p(lpf,Gi)\n",
    "    %set up in pyramid scheme with detection scaled smoothed images\n",
    "    %ef2 is the interest point eigen image\n",
    "    %lpf smoothed by the detection scale gaussian\n",
    "    %Gi = fspecial('gaussian',ceil(7*sigi),sigi);\n",
    "    '''\n",
    "    [fy,fx] = np.gradient(lpf)\n",
    "\n",
    "    [fxy,fxx] = np.gradient(fx)\n",
    "    [fyy,fyx] = np.gradient(fy)\n",
    "    nL = scale**(-2)*np.abs(fxx+fyy)\n",
    "\n",
    "    Mfxx = convolve(np.square(fx),Gi,mode='constant')\n",
    "    Mfxy = convolve(fx*fy,Gi,mode='constant')\n",
    "    Mfyy = convolve(np.square(fy),Gi,mode='constant')\n",
    "\n",
    "    Tr = Mfxx+Mfyy\n",
    "    Det = Mfxx*Mfyy-np.square(Mfxy)\n",
    "    sqrterm = np.sqrt(np.square(Tr)-4*Det)\n",
    "\n",
    "    ef2 = scale**(-2)*0.5*(Tr - sqrterm)\n",
    "    return ef2,nL\n",
    "\n",
    "class ImagePyramid:\n",
    "    def __init__ (self, levels, ratio, sigdec, sigint):\n",
    "        self.levels = levels\n",
    "        self.ratio = ratio\n",
    "        self.images = []\n",
    "        self.lpimages = []\n",
    "        self.sigd = [sigdec]\n",
    "        self.sigi = [sigint]\n",
    "        self.lpfilter = fspecial_gauss(int(np.ceil(7*sigdec)),sigdec)\n",
    "        # Make a note of this 7x7 gaussian kernel, lowering will speed up computation\n",
    "        \n",
    "    def generate_pyramid(self,img):\n",
    "        self.images = [np.float64(img)]\n",
    "        self.lpimages = [convolve(self.images[0],self.lpfilter,mode='constant')]\n",
    "        for k in range(1,self.levels):\n",
    "            #self.images += [cv2.resize(self.images[-1], (0,0), fx=self.ratio,\n",
    "            #                          fy=self.ratio, interpolation=cv2.INTER_LINEAR_EXACT)]\n",
    "            self.images += [imresize(self.images[-1], self.ratio, method='bilinear')]\n",
    "            self.lpimages += [convolve(self.images[-1],self.lpfilter,mode='constant')]\n",
    "            self.sigd += [self.sigd[-1]/self.ratio] #equivalent sigdec at max res\n",
    "            self.sigi += [self.sigi[-1]/self.ratio] \n",
    "\n",
    "            \n",
    "P = ImagePyramid(6,0.75,1,2.75)\n",
    "st = time.time()\n",
    "for i in range(10):\n",
    "    P.generate_pyramid(gr1)\n",
    "print(\"time: \",(time.time()-st)/10)\n",
    "fig, ax1 = plt.subplots(1,1,dpi=200)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(P.lpimages[1],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gi = fspecial_gauss(11, 2.75)\n",
    "lpf = P.lpimages[0]\n",
    "scale = 0.75\n",
    "[eig, nL] = eigen_image_p(lpf,Gi,scale)\n",
    "fig, [ax1,ax2] = plt.subplots(2,1,dpi=200)\n",
    "fig.suptitle('eig and nL images')\n",
    "#a.axis(\"off\")\n",
    "ax1.imshow(eig,cmap='gray'),ax1.axis(\"off\")\n",
    "ax2.imshow(nL,cmap='gray'),ax2.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feat_extract_p2 (P, zrad, Gi):\n",
    "    local_maxima_nhood=3\n",
    "\n",
    "    scales = P.levels\n",
    "    ratio = P.ratio\n",
    "    #E(1).levels = scales;\n",
    "    border = zrad\n",
    "    [rows,cols] = P.lpimages[0].shape\n",
    "\n",
    "    eig = [None] * scales\n",
    "    nL = [None] * scales\n",
    "    border_mask = [None] * scales \n",
    "    regmask=[None] * scales \n",
    "    ivec= [None] * scales \n",
    "    jvec= [None] * scales\n",
    "\n",
    "    for k in range(scales):\n",
    "        [eig[k], nL[k]] = eigen_image_p(P.lpimages[k] , Gi,ratio**(k))\n",
    "        # extract regional max and block out borders (edge effect)\n",
    "\n",
    "        # generate mask for border\n",
    "        border_mask[k] = np.zeros_like(eig[k],dtype=bool)\n",
    "        border_mask[k][border:-border,border:-border]=True\n",
    "\n",
    "        #E(k).regmask = imregionalmax(E(k).eig)\n",
    "        regmask[k] = maximum_filter(eig[k],size=local_maxima_nhood)<=eig[k]\n",
    "\n",
    "        regmask[k] = np.logical_and(regmask[k],border_mask[k])\n",
    "        print(\"K: \",k,\" - \",np.sum(regmask[k]))\n",
    "        #[ivec[k], jvec[k]] = np.nonzero(regmask[k]) #coordinates of 1s in regmask\n",
    "        # Just to match matlab version, can be reverted to optimise\n",
    "        [jvec[k], ivec[k]] = np.nonzero(regmask[k].T)\n",
    "\n",
    "    # INITIALIZE feature positions and scales at highest level\n",
    "    # at highest resolution coordinates of features:\n",
    "    Fivec = ivec[0]\n",
    "    Fjvec = jvec[0]\n",
    "    Fsvec = np.zeros_like(Fivec) #initial scale \n",
    "    Fevec = eig[0][ivec[0],jvec[0]] #access the elements of eig at locations given by ivec,jvec\n",
    "\n",
    "    #i,j position of feature at the characteristic scale\n",
    "    Fsivec = Fivec \n",
    "    Fsjvec = Fjvec\n",
    "\n",
    "    nLvec = nL[0][ivec[0],jvec[0]]\n",
    "    pivec = Fivec\n",
    "    pjvec = Fjvec\n",
    "    pind = np.array(list(range(len(Fivec))))\n",
    "    k = 1\n",
    "\n",
    "    while  (k < scales) & (len(pivec) > 0):\n",
    "        mx = (np.floor(cols*ratio)-1)/(cols-1)  #scale conversion to next level\n",
    "        my = (np.floor(rows*ratio)-1)/(rows-1) \n",
    "\n",
    "        [rows,cols]  = eig[k].shape #dimensions of next level\n",
    "        pendreg = np.zeros_like(pivec)\n",
    "        #sivec = np.round((pivec-1)*my+1).astype(int) #next scale ivec\n",
    "        #sjvec = np.round((pjvec-1)*mx+1).astype(int) #next scale jvec\n",
    "        # match matlab output\n",
    "        sivec = np.round(pivec*my+np.finfo(np.float32).eps).astype(int) #next scale ivec\n",
    "        sjvec = np.round(pjvec*mx+np.finfo(np.float32).eps).astype(int) #next scale jvec\n",
    "\n",
    "        #scipy.io.savemat('py_orig_vecs.mat', mdict={'pysivec': sivec, 'pysjvec':sjvec })\n",
    "\n",
    "        csivec = sivec\n",
    "        csjvec = sjvec\n",
    "        #cloc = sivec+1 + rows*(sjvec)\n",
    "\n",
    "        for u in range(-1,2):  #account for motion of feature points between scales\n",
    "            for v in range(-1,2):\n",
    "\n",
    "                sojvec = sjvec+u #next scale jvec\n",
    "\n",
    "                soivec = sivec+v #next scale ivec\n",
    "\n",
    "                #loc = soivec + rows*(sojvec-1) #index vector of next level\n",
    "                #have to account for motion of feature point at different\n",
    "                #scales - more than just the sampling\n",
    "\n",
    "                uvpend = regmask[k][soivec,sojvec] == 1\n",
    "                pendreg = np.logical_or(pendreg,uvpend)\n",
    "                #print(\"u,v:\",u,v,\" pendreg:\",np.sum(pendreg))\n",
    "                #cloc[uvpend] = loc[uvpend]\n",
    "                #print(\"474: \",uvpend[473])\n",
    "                csivec[uvpend] = soivec[uvpend]\n",
    "                csjvec[uvpend] = sojvec[uvpend]\n",
    "\n",
    "\n",
    "        pend = np.logical_and(pendreg, nL[k][csivec,csjvec] >= nLvec)\n",
    "\n",
    "        pind = pind[pend]\n",
    "\n",
    "        Fsvec[pind] = k #scale is k or larger\n",
    "        Fevec[pind] = eig[k][csivec[pend],csjvec[pend]] #eigen value is given at\n",
    "                                             #level k or larger\n",
    "        Fsivec[pind] = csivec[pend]\n",
    "        Fsjvec[pind] = csjvec[pend]\n",
    "\n",
    "        pivec = csivec[pend]\n",
    "        pjvec = csjvec[pend]\n",
    "        nLvec = nL[k][csivec[pend],csjvec[pend]]\n",
    "        print(np.sum(Fsvec==k))\n",
    "        k = k+1\n",
    "    return Fivec,Fjvec,Fsvec,Fevec,Fsivec,Fsjvec\n",
    "\n",
    "P = ImagePyramid(6,0.75,1,2.75)\n",
    "P.generate_pyramid(gr1)\n",
    "zrad = 22\n",
    "Gi = fspecial_gauss(11, 2.75)\n",
    "\n",
    "out_list = feat_extract_p2(P,zrad,Gi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import sys\n",
    "sys.path.append('/Users/vik748/matlab_imresize/')\n",
    "from imresize import imresize\n",
    "\n",
    "b = gr1[0:10,0:10].astype(float)\n",
    "c = cv2.resize(b, (0,0), fx=0.75,fy=0.75, interpolation=cv2.INTER_LINEAR)\n",
    "d = resize(b,tuple(round(i * .75) for i in b.shape), order=1, mode='constant',anti_aliasing=True,anti_aliasing_sigma=0.25/2)\n",
    "st = time.time()\n",
    "for i in range(10):\n",
    "    e = imresize(np.double(b),0.75,method='bilinear')\n",
    "print (\"time elapsed:\", (time.time()-st)/10)\n",
    "#image, output_shape, order=1, , cval=0, clip=True, preserve_range=False, anti_aliasing=True, anti_aliasing_sigma=None\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, scipy.io\n",
    "\n",
    "#arr = numpy.arange(10)\n",
    "#arr = arr.reshape((3, 3))  # 2d array of 3x3\n",
    "\n",
    "scipy.io.savemat('pyregmask.mat', mdict={'pyregmask': regmask[1]})\n",
    "\n",
    "nL[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvpend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fevec = eig[0](ivec[0] + rows*(jvec[0]-1)) #1D index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(round(i * .75) for i in b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.array([2,3,4,5]);\n",
    "j = np.array([1,2,3,4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slam_env",
   "language": "python",
   "name": "slam_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
